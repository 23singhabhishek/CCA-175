
. Different file formats:
   ======================
1. --as-textfile	      Imports data as plain text (default)
   =======================================================
sqoop import \
--connect 'jdbc:mysql://quickstart.cloudera:3306/retail_db' \
--username retail_db \
--password cloudera \
--table departments \
--as-textfile \
--target-dir=/user/cloudera/sqoop/sqoop-import/txtfil

P.S: Do not create the folder 'txtfil' before executing the command

==============================================================================================================================

2. --as-avrodatafile	  Imports data to Avro Data Files
   ===================================================
i. avro for table
   --------------
sqoop import \
--connect 'jdbc:mysql://quickstart.cloudera:3306/retail_db' \
--username retail_dba \
--password cloudera \
--table categories \
--as-avrodatafile \
--target-dir=/user/cloudera/sqoop/sqoop-import/avrfil  \
--outdir java_files

[cloudera@quickstart ~]$ hdfs dfs -cat sqoop/sqoop-import/avrfil/p*
Objavro.schema�{"type":"record","name":"categories","doc":"Sqoop import of categories","fields":[{"name":"category_id","type":["null","int"],"default":null,"columnName":"category_id","sqlType":"4"},{"name":"category_department_id","type":["null","int"],"default":null,"columnName":"category_department_id","sqlType":"4"},{"name":"category_name","type":["null","string"],"default":null,"columnName":"category_name","sqlType":"12"}],"tableName":"categories"}�̍h�;KVDQ?+��Football
                                                                                                                                                                Soccer&Baseball & SoftballBasketball

[cloudera@quickstart ~]$ ls -ltr java_files
-rw-rw-r-- 1 cloudera cloudera 14092 Jan 27 09:00 categories.java
-rw-rw-r-- 1 cloudera cloudera   594 Jan 27 09:01 categories.avsc


ii. avro for query
    --------------

sqoop import --connect 'jdbc:mysql://quickstart.cloudera:3306/retail_db' --username retail_dba --password cloudera 
--query 'select * from orders WHERE $CONDITIONS and order_status = "PENDING_PAYMENT"' --as-avrodatafile 
--target-dir=/user/cloudera/sqoop/sqoop-import/avrqry  --outdir java_files --split-by order_id


[cloudera@quickstart ~]$ hdfs dfs -cat sqoop/sqoop-import/avrqry/p*
PENDING_PAYMENT����ƾQ�@PENDING_PAYMENT�����Q�DPENDING_PAYMENT��׏�QҝPENDING_PAYMENT��׏�Q��PENDINPENDING_PAYMENT������Q�PENDING_PAYMENT������Q�xPENDING_PAYMENT������Q�1PENDING_PAYMENT������Q�PENDING_PAYMENT������Q��PENDING_PAYMENT����

[cloudera@quickstart ~]$ ls -ltr java_files
-rw-rw-r-- 1 cloudera cloudera 16435 Jan 27 09:47 QueryResult.java
-rw-rw-r-- 1 cloudera cloudera   730 Jan 27 09:47 AutoGeneratedSchema.avsc

iii. avro for columns + query:
     ------------------------
sqoop import --connect 'jdbc:mysql://quickstart.cloudera:3306/retail_db' --username retail_dba --password cloudera \
--query 'select * from orders WHERE $CONDITIONS and order_status = "PENDING_PAYMENT"' \
--as-avrodatafile --target-dir=/user/cloudera/sqoop/sqoop-import/avrcol \
--columns 'order_id, order_date,order_customer_id'  --outdir java_files --split-by order_id

[cloudera@quickstart ~]$ hdfs dfs -cat sqoop/sqoop-import/avrcol/p*
PENDING_PAYMENT������Q�PENDING_PAYMENT������Q�xPENDING_PAYMENT������Q�1PENDING_PAYMENT������Q�PENDING_PAYMENT������Q��PENDING_PAYMENT�����

[cloudera@quickstart ~]$ ls -ltr java_files
java or avsc file is not generated

iv. avro for columns:
    --------------
sqoop import --connect 'jdbc:mysql://quickstart.cloudera:3306/retail_db' --username retail_dba --password cloudera \
--target-dir sqoop/sqoop-import/avrcolq --m 2 --as-avrodatafile --table orders \
--columns 'order_id,order_status,order_customer_id' --outdir java_files

[cloudera@quickstart ~]$ hdfs dfs -cat sqoop/sqoop-import/avrcolq/p*
CTED_FRAUD��PROCESSING���COMPLETEڡ�PENDING���COMPLETE��PROCESSING�2�COMPLETE���COMPLETE�w�
                                                                                                                              CLOSED���COMPLETE�e�CANCELED���

[cloudera@quickstart ~]$ ls -ltr java_files
-rw-rw-r-- 1 cloudera cloudera 13631 Jan 27 10:44 orders.java
-rw-rw-r-- 1 cloudera cloudera   564 Jan 27 10:44 orders.avsc


P.S: Do not create the folder 'avrfil' before executing the command
Delimiters do not have much value when it comes to storing in avro format.
Its more like JSON format.

outdir java_files: This directory is created in the folder where the sqoop command runs. The directory would have java files 
created for the imported tables.
.avsc: the tbl-name.avsc file is also created in the same directory as java_files. It has the table schema.

******************************************************************************************************************************

Creating hive table from avsc :
-----------------------------
- A file with extension avsc will be created under the directory from which sqoop import is executed
-- Copy avsc file to HDFS location
-- Create hive table with LOCATION to /user/cloudera/departments and TBLPROPERTIES pointing to avsc file

hadoop fs -put java_files/*.avsc /user/cloudera/avsc/

[cloudera@quickstart ~]$ hadoop fs -ls  /user/cloudera/avsc/
Found 4 items
-rw-r--r--   1 cloudera cloudera        730 2017-01-27 11:23 /user/cloudera/avsc/AutoGeneratedSchema.avsc
-rw-r--r--   1 cloudera cloudera        594 2017-01-27 11:23 /user/cloudera/avsc/categories.avsc
-rw-r--r--   1 cloudera cloudera        375 2017-01-27 11:23 /user/cloudera/avsc/dept.avsc
-rw-r--r--   1 cloudera cloudera        564 2017-01-27 11:23 /user/cloudera/avsc/orders.avsc

The data unload for the above is present in the below locations:
AutoGeneratedSchema  : hdfs://quickstart.cloduera:8020/user/cloudera/sqoop/sqoop-import/avrqry
categories           : hdfs://quickstart.cloudera:8020/user/cloudera/sqoop/sqoop-import/avrfil
dept                 : hdfs:///user/cloudera/sqoop/sqoop-import/avrdpt
orders               : hdfs://quickstart.cloudera:8020/sqoop/sqoop-import/avrcolq

******************************************************************************************************************************

CREATE EXTERNAL TABLE avsc.auto
ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.avro.AvroSerDe'
STORED AS INPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerInputFormat'
OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerOutputFormat'
LOCATION 'hdfs://quickstart.cloudera:8020/user/cloudera/sqoop/sqoop-import/avrqry'
TBLPROPERTIES ('avro.schema.url'='hdfs://quickstart.cloudera:8020/user/cloudera/avsc/AutoGeneratedSchema.avsc');

hive> select * from avsc.auto limit 10;
OK
2	1374735600000	256	PENDING_PAYMENT
9	1374735600000	5657	PENDING_PAYMENT
10	1374735600000	5648	PENDING_PAYMENT
13	1374735600000	9149	PENDING_PAYMENT

******************************************************************************************************************************

CREATE EXTERNAL TABLE avsc.categories
ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.avro.AvroSerDe'
STORED AS INPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerInputFormat'
OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerOutputFormat'
LOCATION 'hdfs://quickstart.cloudera:8020/user/cloudera/sqoop/sqoop-import/avrfil'
TBLPROPERTIES ('avro.schema.url'='avsc/categories.avsc');

hive> select * from avsc.categories limit 10;
OK
1	2	Football
2	2	Soccer
3	2	Baseball & Softball
4	2	Basketball
5	2	Lacrosse

******************************************************************************************************************************

CREATE EXTERNAL TABLE avsc.dept
ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.avro.AvroSerDe'
STORED AS INPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerInputFormat'
OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerOutputFormat'
LOCATION 'hdfs:///user/cloudera/sqoop/sqoop-import/avrdpt'
TBLPROPERTIES ('avro.schema.url'='hdfs://quickstart.cloudera:8020/user/cloudera/avsc/dept.avsc');

hive> select * from avsc.dept limit 10;
OK
2	Fitness
3	Footwear
4	Apparel
5	Golf
6	Outdoors
7	Fan Shop
NULL	NULL

******************************************************************************************************************************

CREATE EXTERNAL TABLE avsc.orders
ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.avro.AvroSerDe'
STORED AS INPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerInputFormat'
OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerOutputFormat'
LOCATION 'hdfs://quickstart.cloudera:8020/user/cloudera/sqoop/sqoop-import/avrcolq'
TBLPROPERTIES ('avro.schema.url'='avsc/orders.avsc');

hive> select * from avsc.orders limit 10;
OK
1	CLOSED	11599
2	PENDING_PAYMENT	256
3	COMPLETE	12111
4	CLOSED	8827

P.S: LOCATION parameter has to have the absolute path (starting with hdfs://)

==============================================================================================================================

3. --as-sequencefile	  Imports data to SequenceFiles
   =================================================
sqoop import \
--connect 'jdbc:mysql://quickstart.cloudera:3306/retail_db' \
--username retail_db \
--password cloudera \
--table departments \
--as-sequencefile \
--target-dir=/user/cloudera/sqoop/sqoop-import/seqfil \
--outdir java_files

P.S: Do not create the folder 'seqfil' before executing the command
Delimiters by default is comma. if delimiters are specified during import then the same should be used while export.

4. --as-parquetfile	  Imports data to Parquet Files
   =================================================
sqoop import \
--connect 'jdbc:mysql://quickstart.cloudera:3306/retail_db' \
--username retail_db \
--password cloudera \
--table departments \
--as-parquetfile \
--target-dir /user/cloudera/sqoop/sqoopprq/prqfil  \
--outdir java_files

P.S: Do not create the folder 'prqfil' before executing the command
Target directory should not have any special characters in the name

********************************************************************************************************************************
********************************************************************************************************************************
