
I. Table without primary key :
   -------------------------
1. Basic export:- Create an empty table in mysql ordexp with no primary key and export the data.
   ------------
mysql> describe ordexp;
+-------------------+-------------+------+-----+---------+-------+
| Field             | Type        | Null | Key | Default | Extra |
+-------------------+-------------+------+-----+---------+-------+
| order_id          | int(11)     | NO   |     | 0       |       |
| order_date        | datetime    | NO   |     | NULL    |       |
| order_customer_id | int(11)     | NO   |     | NULL    |       |
| order_status      | varchar(45) | NO   |     | NULL    |       |
+-------------------+-------------+------+-----+---------+-------+
4 rows in set (0.00 sec)

sqoop export --connect 'jdbc:mysql://quickstart.cloudera:3306/retail_db' --username retail_dba --password cloudera \
--export-dir /user/cloudera/sqoop/sqoop-export/ord \
--table ordexp \
--m 2

Records exported : 20
mysql> ordexp --> count --> 20

Conclusion: 
----------
As the table is empty the records were inserted.
On running the same command again, the records present in the export-dir were inserted to the table. so, total count = 40


2. using option update-mode updateonly: 
   -----------------------------------
   Include the option update-mode updateonly (without using update-key) and load the data to the table from the same file as 
   used in step (1). 
   
a. sqoop export --connect 'jdbc:mysql://quickstart.cloudera:3306/retail_db' --username retail_dba --password cloudera \
--table ordexp --m 2 --export-dir sqoop/sqoop-export/ord \
--update-mode updateonly

Conclusion: 
----------
As update-key is not mentioned, records were inserted to the table, total rec cnt in ordexp = 60

mysql> select * from ordexp where order_id in (1,2,5,7,0);
+----------+---------------------+-------------------+-----------------+
| order_id | order_date          | order_customer_id | order_status    |
+----------+---------------------+-------------------+-----------------+
|        1 | 2013-07-25 00:00:00 |             11599 | CLOSED          |
|        2 | 2013-07-25 00:00:00 |               256 | PENDING_PAYMENT |
|        5 | 2013-07-25 00:00:00 |             11318 | COMPLETE        |
|        7 | 2013-07-25 00:00:00 |              4530 | COMPLETE        |
|        1 | 2013-07-25 00:00:00 |             11599 | CLOSED          |
|        2 | 2013-07-25 00:00:00 |               256 | PENDING_PAYMENT |
|        5 | 2013-07-25 00:00:00 |             11318 | COMPLETE        |
|        7 | 2013-07-25 00:00:00 |              4530 | COMPLETE        |
|        1 | 2013-07-25 00:00:00 |             11599 | CLOSED          |
|        2 | 2013-07-25 00:00:00 |               256 | PENDING_PAYMENT |
|        5 | 2013-07-25 00:00:00 |             11318 | COMPLETE        |
|        7 | 2013-07-25 00:00:00 |              4530 | COMPLETE        |
+----------+---------------------+-------------------+-----------------+
12 rows in set (0.01 sec)

b. Include the option update-key and in the source file have some changes for few records of the table
   ---------------------------------------------------------------------------------------------------
In the ord1 file, below changes were made
customer-ids for the orders with order_id 1, 2 have been modified to 11600 and 257
1,2013-07-25 00:00:00.0,11600,CLOSED
2,2013-07-25 00:00:00.0,257,PENDING_PAYMENT

order_dates have been modified for 5 and 7
5,2013-07-26 00:00:00.0,11318,COMPLETE
6,2013-07-25 00:00:00.0,7130,COMPLETE
7,2013-07-26 00:00:00.0,4530,COMPLETE

sqoop export --connect 'jdbc:mysql://quickstart.cloudera:3306/retail_db' --username retail_dba --password cloudera \
--table ordexp --m 2 --export-dir sqoop/sqoop-export/ord1 \
--update-mode updateonly  \
--update-key order_id

Conclusion: Records were updated. No recs were inserted. Rec cnt in ordexp = 60
----------

mysql> select * from ordexp where order_id in (1,2,5,7,0);
+----------+---------------------+-------------------+-----------------+
| order_id | order_date          | order_customer_id | order_status    |
+----------+---------------------+-------------------+-----------------+
|        1 | 2013-07-25 00:00:00 |             11600 | CLOSED          |
|        2 | 2013-07-25 00:00:00 |               257 | PENDING_PAYMENT |
|        5 | 2013-07-26 00:00:00 |             11318 | COMPLETE        |
|        7 | 2013-07-26 00:00:00 |              4530 | COMPLETE        |
|        1 | 2013-07-25 00:00:00 |             11600 | CLOSED          |
|        2 | 2013-07-25 00:00:00 |               257 | PENDING_PAYMENT |
|        5 | 2013-07-26 00:00:00 |             11318 | COMPLETE        |
|        7 | 2013-07-26 00:00:00 |              4530 | COMPLETE        |
|        1 | 2013-07-25 00:00:00 |             11600 | CLOSED          |
|        2 | 2013-07-25 00:00:00 |               257 | PENDING_PAYMENT |
|        5 | 2013-07-26 00:00:00 |             11318 | COMPLETE        |
|        7 | 2013-07-26 00:00:00 |              4530 | COMPLETE        |
+----------+---------------------+-------------------+-----------------+


3. using option update-mode allowinsert:
   -------------------------------------
   Use the same file as used in step (2b) and run the export command with option allowinsert and update-key mentioned.
   
a. sqoop export --connect 'jdbc:mysql://quickstart.cloudera:3306/retail_db' --username retail_dba --password cloudera \
--table ordexp --m 2 --export-dir sqoop/sqoop-export/ord1 \
--update-mode allowinsert  \
--update-key order_id

Conclusion: Records were inserted. mysql count = 80
----------

b. In the input file have one new rec and one existing rec with no changes. 2 records with one new record and the other existing rec
[cloudera@quickstart ~]$ hdfs dfs -cat sqoop/sqoop-export/ord2
   0,2013-07-25 00:00:00.0,12111,COMPLETE
   4,2013-07-25 00:00:00.0,8827,CLOSED

sqoop export --connect 'jdbc:mysql://quickstart.cloudera:3306/retail_db' --username retail_dba --password cloudera \
--table ordexp --m 2 --export-dir sqoop/sqoop-export/ord2 \
--update-mode allowinsert  \
--update-key order_id

Conclusion: Both records were inserted.
----------

c. In the input file have one new rec and one existing rec with changes. 2 records with one new rec and the other existing rec 
but with changes
[cloudera@quickstart ~]$ hdfs dfs -cat sqoop/sqoop-export/ord3
21,2013-07-25 00:00:00.0,12111,COMPLETE
8,2013-07-25 00:00:00.0,8827,COMPLETE

mysql> select * from ordexp where order_id in (21,8);
+----------+---------------------+-------------------+--------------+
| order_id | order_date          | order_customer_id | order_status |
+----------+---------------------+-------------------+--------------+
|        8 | 2013-07-25 00:00:00 |              2911 | PROCESSING   |
|        8 | 2013-07-25 00:00:00 |              2911 | PROCESSING   |
|        8 | 2013-07-25 00:00:00 |              2911 | PROCESSING   |
|        8 | 2013-07-25 00:00:00 |              2911 | PROCESSING   |
+----------+---------------------+-------------------+--------------+
4 rows in set (0.00 sec)

sqoop export --connect 'jdbc:mysql://quickstart.cloudera:3306/retail_db' --username retail_dba --password cloudera \
--table ordexp --m 2 --export-dir sqoop/sqoop-export/ord3 \
--update-mode allowinsert  \
--update-key order_id

Both recs were inserted. 
mysql> select * from ordexp where order_id in (21,8);
+----------+---------------------+-------------------+--------------+
| order_id | order_date          | order_customer_id | order_status |
+----------+---------------------+-------------------+--------------+
|        8 | 2013-07-25 00:00:00 |              2911 | PROCESSING   |
|        8 | 2013-07-25 00:00:00 |              2911 | PROCESSING   |
|        8 | 2013-07-25 00:00:00 |              2911 | PROCESSING   |
|        8 | 2013-07-25 00:00:00 |              2911 | PROCESSING   |
|       21 | 2013-07-25 00:00:00 |             12111 | COMPLETE     |
|        8 | 2013-07-25 00:00:00 |              8827 | COMPLETE     |
+----------+---------------------+-------------------+--------------+
6 rows in set (0.00 sec)


4. Using option columns.
   --------------------

Create a table orditmsub which is having the columns.
Now, export the data unload from the table order_items for the selected columns.

a. First time insert


b. update-mode (allowinsert)


c. update-mode (updateonly)
Make changes to multiple column data in the source file but include only one of the columns


========================================================================================================================
Table with primary key:
---------------------
mysql> describe ordexp1;
+-------------------+-------------+------+-----+---------+-------+
| Field             | Type        | Null | Key | Default | Extra |
+-------------------+-------------+------+-----+---------+-------+
| order_id          | int(11)     | NO   | PRI | 0       |       |
| order_date        | datetime    | NO   |     | NULL    |       |
| order_customer_id | int(11)     | NO   |     | NULL    |       |
| order_status      | varchar(45) | NO   |     | NULL    |       |
+-------------------+-------------+------+-----+---------+-------+

mysql> ordexp1 --> count --> 20

sqoop export --connect 'jdbc:mysql://quickstart.cloudera:3306/retail_db' --username retail_dba --password cloudera \
--export-dir sqoop/sqoop-import/orders/part-m-00000 --table ordexp1  --m 2 

The export job has failed. The input file has 17221 records. But the count in table indicates 120 recs. So, some records from
the input file has been copied. The job must have failed when the check on primary key failed.



i. Without prim key

a. The orders table data is taken but with only first 20 records (order id 1 to order id 20). No change in the input date



The 20 records present in the input file has been appended to the table. Now the rec count is 17241 + 20 = 17261 records

b. 4 records have been modified. 

mysql> select * from ordexp where order_id in (1,2,5,7,0);
+----------+---------------------+-------------------+-----------------+
| order_id | order_date          | order_customer_id | order_status    |
+----------+---------------------+-------------------+-----------------+
|        1 | 2013-07-25 00:00:00 |             11599 | CLOSED          |
|        2 | 2013-07-25 00:00:00 |               256 | PENDING_PAYMENT |
|        5 | 2013-07-25 00:00:00 |             11318 | COMPLETE        |
|        7 | 2013-07-25 00:00:00 |              4530 | COMPLETE        |
|        1 | 2013-07-25 00:00:00 |             11599 | CLOSED          |
|        2 | 2013-07-25 00:00:00 |               256 | PENDING_PAYMENT |
|        5 | 2013-07-25 00:00:00 |             11318 | COMPLETE        |
|        7 | 2013-07-25 00:00:00 |              4530 | COMPLETE        |
|        1 | 2013-07-25 00:00:00 |             11599 | CLOSED          |
|        2 | 2013-07-25 00:00:00 |               256 | PENDING_PAYMENT |
|        5 | 2013-07-25 00:00:00 |             11318 | COMPLETE        |
|        7 | 2013-07-25 00:00:00 |              4530 | COMPLETE        |
+----------+---------------------+-------------------+-----------------+

customer-ids for the orders with order_id 1, 2 have been modified to 11600 and 257
1,2013-07-25 00:00:00.0,11600,CLOSED
2,2013-07-25 00:00:00.0,257,PENDING_PAYMENT

order_dates have been modified for 5 and 7
5,2013-07-26 00:00:00.0,11318,COMPLETE
6,2013-07-25 00:00:00.0,7130,COMPLETE
7,2013-07-26 00:00:00.0,4530,COMPLETE

sqoop export --connect 'jdbc:mysql://quickstart.cloudera:3306/retail_db' --username retail_dba --password cloudera \
--table ordexp --m 2 --export-dir sqoop/sqoop-export/ord1 \
--update-mode updateonly



c. Update + insert rec:

with prim key



3. using option update-mode allowinsert



4. columns


staging table
******************************************************************************************************************************
******************************************************************************************************************************
Create table in retail_db with no data (the where cond 1 = 2 is always FALSE, hence the data is not inserted into the newly
created table). No primary key gets created.

create table order_items_export as select * from order_items where 1= 2;

sqoop export \
--connect 'jdbc:mysql://quickstart.cloudera:3306/retail_db' \
--username retail_dba \
--password cloudera \
--export-dir /user/cloudera/sqoop/sqoop-import/orderitems/part* \
--table order_items_export \
--m 5 \
--batch

mysql> select count(1) from retail_db.order_items_export;
+----------+
| count(1) |
+----------+
|   172198 |
+----------+
1 row in set (0.39 sec)


run the same command again

The records are inserted again

mysql> select count(1) from retail_db.order_items_export;
+----------+
| count(1) |
+----------+
|   344396 |
+----------+
1 row in set (2.34 sec)



STAGING TABLE CONCEPT: used only in insert mode. works for tables with no primary key
=====================
Create table depts_exp similar to departments table;

mysql> select * from depts_exp;
+---------------+-----------------+
| department_id | department_name |
+---------------+-----------------+
|             2 | Fitness         |
|             3 | Footwear        |
|             4 | Apparel         |
|             5 | Golf            |
|             6 | Outdoors        |
|             7 | Fan Shop        |
|            10 | Test10          |
|            20 | Test20          |
|            30 | Test30          |
|            40 | Test40          |
+---------------+-----------------+
10 rows in set (0.00 sec)

mysql> describe depts_exp
    -> ;
+-----------------+-------------+------+-----+---------+-------+
| Field           | Type        | Null | Key | Default | Extra |
+-----------------+-------------+------+-----+---------+-------+
| department_id   | int(11)     | NO   |     | 0       |       |
| department_name | varchar(45) | NO   |     | NULL    |       |
+-----------------+-------------+------+-----+---------+-------+
2 rows in set (0.00 sec)

*****


UPDATE MODE (UPDATEONLY):
==========
sqoop export \
--connect 'jdbc:mysql://quickstart.cloudera:3306/retail_db' \
--username retail_dba --password cloudera \
--export-dir sqoop/sqoop-export/depts_exp \
--table departments \
--update-mode updateonly \
--update-key department_id 

mysql> select * from departments;
+---------------+-----------------+
| department_id | department_name |
+---------------+-----------------+
|             2 | Fitness         |
|             3 | Footwear        |
|             4 | Apparel         |
|             5 | Golf            |
|             6 | Outdoors        |
|             7 | Fan Shop        |
|            10 | Test10          |
|            20 | Test20          |
|            30 | Test30          |
|            40 | Test40          |
+---------------+-----------------+
10 rows in set (0.00 sec)

[cloudera@quickstart ~]$ hdfs dfs -cat sqoop/sqoop-export/*
7,FanShop
9,Test09
30,Test 30


mysql> select * from departments;
+---------------+-----------------+
| department_id | department_name |
+---------------+-----------------+
|             2 | Fitness         |
|             3 | Footwear        |
|             4 | Apparel         |
|             5 | Golf            |
|             6 | Outdoors        |
|             7 | FanShop         |
|            10 | Test10          |
|            20 | Test20          |
|            30 | Test 30         |
|            40 | Test40          |
+---------------+-----------------+
10 rows in set (0.09 sec)

UPDATE MODE(ALLOWINSERT)
=====================
sqoop export \
--connect 'jdbc:mysql://quickstart.cloudera:3306/retail_db' \
--username retail_dba --password cloudera \
--export-dir sqoop/sqoop-export/depts_exp1 \
--table departments \
--update-mode allowinsert \
--update-key department_id 

[cloudera@quickstart ~]$ hdfs dfs -cat sqoop/sqoop-export/depts_exp1
7,Fan Shop
9,Test09
30,Test30

mysql> select * from departments;
+---------------+-----------------+
| department_id | department_name |
+---------------+-----------------+
|             2 | Fitness         |
|             3 | Footwear        |
|             4 | Apparel         |
|             5 | Golf            |
|             6 | Outdoors        |
|             7 | Fan Shop        |
|             9 | Test09          |
|            10 | Test10          |
|            20 | Test20          |
|            30 | Test30          |
|            40 | Test40          |
+---------------+-----------------+
11 rows in set (0.15 sec)



P.S: When trying to run the command in insert mode, the job failed due to 
duplicate entry for the keys (7,9,30) specified in the export file 

sqoop export \
--connect 'jdbc:mysql://quickstart.cloudera:3306/retail_db' \
--username retail_dba --password cloudera \
--export-dir sqoop/sqoop-export/depts_exp1 \
--table departments 


Now, lets try running the same command with an additional new key present in the export file.

[cloudera@quickstart ~]$ hdfs dfs -cat sqoop/sqoop-export/depts_exp2
7,Fan Shop
9,Test09
30,Test30
50,Test50

sqoop export \
--connect 'jdbc:mysql://quickstart.cloudera:3306/retail_db' \
--username retail_dba --password cloudera \
--export-dir sqoop/sqoop-export/depts_exp2 \
--table departments 


This also fails but the record is inserted
mysql> select * from departments;
+---------------+-----------------+
| department_id | department_name |
+---------------+-----------------+
|             2 | Fitness         |
|             3 | Footwear        |
|             4 | Apparel         |
|             5 | Golf            |
|             6 | Outdoors        |
|             7 | Fan Shop        |
|             9 | Test09          |
|            10 | Test10          |
|            20 | Test20          |
|            30 | Test30          |
|            40 | Test40          |
|            50 | Test50          |
+---------------+-----------------+
12 rows in set (0.00 sec)


*********************************************************************************************************************************
*********************************************************************************************************************************
*********************************************************************************************************************************
*********************************************************************************************************************************


Table 27. Common argument

Argument	Description
--connect <jdbc-uri>	Specify JDBC connect string
--connection-manager <class-name>	Specify connection manager class to use
--driver <class-name>	Manually specify JDBC driver class to use
--hadoop-mapred-home <dir>	Override $HADOOP_MAPRED_HOME
--help	Print usage instructions
--password-file	Set path for a file containing the authentication password
-P	Read password from console
--password <password>	Set authentication password
--username <username>	Set authentication username
--verbose	Print more information while working
--connection-param-file <filename>	Optional properties file that provides connection parameters
--relaxed-isolation	Set connection transaction isolation to read uncommitted for the mappers.

Table 28. Validation arguments More Details

Argument	Description
--validate	Enable validation of data copied, supports single table copy only.
--validator <class-name>	Specify validator class to use.
--validation-threshold <class-name>	Specify validation threshold class to use.
--validation-failurehandler <class-name>	Specify validation failure handler class to use.

Table 29. Export control arguments:

Argument	Description
--columns <col,col,colâ€¦>	Columns to export to table
--direct	Use direct export fast path
--export-dir <dir>	HDFS source path for the export
-m,--num-mappers <n>	Use n map tasks to export in parallel
--table <table-name>	Table to populate
--call <stored-proc-name>	Stored Procedure to call
--update-key <col-name>	Anchor column to use for updates. Use a comma separated list of columns if there are more than one column.
--update-mode <mode>	Specify how updates are performed when new rows are found with non-matching keys in database.
Legal values for mode include updateonly (default) and allowinsert.
--input-null-string <null-string>	The string to be interpreted as null for string columns
--input-null-non-string <null-string>	The string to be interpreted as null for non-string columns
--staging-table <staging-table-name>	The table in which data will be staged before being inserted into the destination table.
--clear-staging-table	Indicates that any data present in the staging table can be deleted.
--batch	Use batch mode for underlying statement execution.
